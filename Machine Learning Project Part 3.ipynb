{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Machine Learning Project Part 3\n",
    "\n",
    "In the first two parts of this project, we implemented the first 6 steps of the machine learning pipeline:\n",
    "\n",
    "1. Data cleaning and structuring\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Engineering/Selection\n",
    "4. Evaluate/compare several machine learning models on a performance metric\n",
    "5. Perform hyperparameter tuning on the best model\n",
    "6. Evaluate the best model on the testing set\n",
    "7. Interpret the model results\n",
    "8. Draw conclusions and write a well-documented report\n",
    "\n",
    "In this notebook, we will concentrate on the last two steps, which is where the most value in the project comes from. We have our final model and the results, but what can we take away from the results? To answer this question, we can employ a variety of techniques to try and understand our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "We will use a similar stack of data science and machine learning imports as in the previous parts. These are all fairly standard tools of the trade, so being familiar with them will be very useful in your data science career!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Matplotlib and seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Imputing missing values\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Size:  (6749, 77)\n",
      "Testing Feature Size:   (2893, 77)\n",
      "Training Labels Size:   (6749, 1)\n",
      "Testing Labels Size:    (2893, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read in data into dataframes from GitHub url\n",
    "X = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/training_features.csv', header = 0)\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/testing_features.csv', header = 0)\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/training_labels.csv', header = 0)\n",
    "y_test = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/testing_labels.csv', header = 0)\n",
    "\n",
    "# Display sizes of data\n",
    "print('Training Feature Size: ', X.shape)\n",
    "print('Testing Feature Size:  ', X_test.shape)\n",
    "print('Training Labels Size:  ', y.shape)\n",
    "print('Testing Labels Size:   ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all problem values are recorded as np.nan\n",
    "X = X.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "X_test = X_test.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "\n",
    "# Create an imputer object with a median filling strategy\n",
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "# Train on the training features\n",
    "imputer.fit(X)\n",
    "\n",
    "# Transform both training data and testing data\n",
    "X = imputer.transform(X)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Sklearn wants the labels as one-dimensional vectors\n",
    "y = np.array(y).reshape((-1,))\n",
    "y_test = np.array(y_test).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean absolute error\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor( n_estimators=300, max_depth=60, max_features='auto', criterion = 'mae',\n",
    "                              min_samples_leaf=1, n_jobs=-1, random_state=42, verbose=1)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Make predictions on the test set\n",
    "model_pred = model.predict(X_test)\n",
    "\n",
    "print('Final Model Performance on the test set: MAE = %0.4f' % mae(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance on the test set: MAE = 9.4806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#  Make predictions on the test set\n",
    "model_pred = model.predict(X_test)\n",
    "\n",
    "print('Final Model Performance on the test set: MAE = %0.4f' % mae(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
