{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Machine Learning Project Part 2\n",
    "\n",
    "In this series of notebooks, we are working on a supervised, regression machine learning problem. Using real-world New York City building energy data, we want to predict the Energy Star Score and determine the factors that influence the score.\n",
    "\n",
    "We are working through the outline of a machine learning project:\n",
    "\n",
    "1. Data cleaning and structuring\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Engineering/Selection\n",
    "4. Evaluate/compare several machine learning models on a performance metric\n",
    "5. Perform hyperparameter tuning on the best model\n",
    "6. Evaluate the best model on the testing set\n",
    "7. Interpret the model results\n",
    "8. Draw conclusions and write a well-documented report\n",
    "\n",
    "The first notebook covered steps 1-3, and in this notebook, we will cover 4-6. I skip over all of the details of the machine learning models used here to focus on the implementation, but I would suggest reading this excellent book to get an idea of how they work and how to use them effectively in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports \n",
    "\n",
    "We will use most of the same imports as for the first part with the addition of some machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Matplotlib and seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Imputing missing values\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "Here we will read in the formatted data that we cleaned in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Size:  (6749, 77)\n",
      "Testing Feature Size:   (2893, 77)\n",
      "Training Labels Size:   (6749, 1)\n",
      "Testing Labels Size:    (2893, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read in data into dataframes from GitHub url\n",
    "X = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/training_features.csv', header = 0)\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/testing_features.csv', header = 0)\n",
    "y = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/training_labels.csv', header = 0)\n",
    "y_test = pd.read_csv('https://raw.githubusercontent.com/WillKoehrsen/machine-learning-project/master/data/testing_labels.csv', header = 0)\n",
    "\n",
    "# Display sizes of data\n",
    "print('Training Feature Size: ', X.shape)\n",
    "print('Testing Feature Size:  ', X_test.shape)\n",
    "print('Training Labels Size:  ', y.shape)\n",
    "print('Testing Labels Size:   ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, here is what the formatted data looks like. In the first notebook, we engineered a number features by taking the natural log of the variables and we selected features by removing highly collinear features. Mostly we are focusing on numerical features, but we also included two categorical features that we saw are related to the Energy Star Score. These categorical variables have been one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Property Id</th>\n",
       "      <th>DOF Gross Floor Area</th>\n",
       "      <th>Largest Property Use Type - Gross Floor Area (ft²)</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Number of Buildings - Self-reported</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>Weather Normalized Site EUI (kBtu/ft²)</th>\n",
       "      <th>Weather Normalized Site Electricity Intensity (kWh/ft²)</th>\n",
       "      <th>Natural Gas Use (kBtu)</th>\n",
       "      <th>Weather Normalized Site Natural Gas Use (therms)</th>\n",
       "      <th>Indirect GHG Emissions (Metric Tons CO2e)</th>\n",
       "      <th>Water Use (All Water Sources) (kgal)</th>\n",
       "      <th>Water Intensity (All Water Sources) (gal/ft²)</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>log_Site EUI (kBtu/ft²)</th>\n",
       "      <th>log_Weather Normalized Site EUI (kBtu/ft²)</th>\n",
       "      <th>log_Weather Normalized Site Electricity Intensity (kWh/ft²)</th>\n",
       "      <th>log_Direct GHG Emissions (Metric Tons CO2e)</th>\n",
       "      <th>log_Water Use (All Water Sources) (kgal)</th>\n",
       "      <th>log_Water Intensity (All Water Sources) (gal/ft²)</th>\n",
       "      <th>Borough_Staten Island</th>\n",
       "      <th>Largest Property Use Type_Adult Education</th>\n",
       "      <th>Largest Property Use Type_Ambulatory Surgical Center</th>\n",
       "      <th>Largest Property Use Type_Automobile Dealership</th>\n",
       "      <th>Largest Property Use Type_Bank Branch</th>\n",
       "      <th>Largest Property Use Type_College/University</th>\n",
       "      <th>...</th>\n",
       "      <th>Largest Property Use Type_Museum</th>\n",
       "      <th>Largest Property Use Type_Non-Refrigerated Warehouse</th>\n",
       "      <th>Largest Property Use Type_Other</th>\n",
       "      <th>Largest Property Use Type_Other - Education</th>\n",
       "      <th>Largest Property Use Type_Other - Entertainment/Public Assembly</th>\n",
       "      <th>Largest Property Use Type_Other - Lodging/Residential</th>\n",
       "      <th>Largest Property Use Type_Other - Mall</th>\n",
       "      <th>Largest Property Use Type_Other - Public Services</th>\n",
       "      <th>Largest Property Use Type_Other - Recreation</th>\n",
       "      <th>Largest Property Use Type_Other - Services</th>\n",
       "      <th>Largest Property Use Type_Other - Specialty Hospital</th>\n",
       "      <th>Largest Property Use Type_Other - Technology/Science</th>\n",
       "      <th>Largest Property Use Type_Outpatient Rehabilitation/Physical Therapy</th>\n",
       "      <th>Largest Property Use Type_Parking</th>\n",
       "      <th>Largest Property Use Type_Performing Arts</th>\n",
       "      <th>Largest Property Use Type_Pre-school/Daycare</th>\n",
       "      <th>Largest Property Use Type_Refrigerated Warehouse</th>\n",
       "      <th>Largest Property Use Type_Repair Services (Vehicle, Shoe, Locksmith, etc.)</th>\n",
       "      <th>Largest Property Use Type_Residence Hall/Dormitory</th>\n",
       "      <th>Largest Property Use Type_Residential Care Facility</th>\n",
       "      <th>Largest Property Use Type_Restaurant</th>\n",
       "      <th>Largest Property Use Type_Retail Store</th>\n",
       "      <th>Largest Property Use Type_Self-Storage Facility</th>\n",
       "      <th>Largest Property Use Type_Senior Care Community</th>\n",
       "      <th>Largest Property Use Type_Social/Meeting Hall</th>\n",
       "      <th>Largest Property Use Type_Strip Mall</th>\n",
       "      <th>Largest Property Use Type_Supermarket/Grocery Store</th>\n",
       "      <th>Largest Property Use Type_Urgent Care/Clinic/Other Outpatient</th>\n",
       "      <th>Largest Property Use Type_Wholesale Club/Supercenter</th>\n",
       "      <th>Largest Property Use Type_Worship Facility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4212</td>\n",
       "      <td>4932827</td>\n",
       "      <td>111567.0</td>\n",
       "      <td>98016.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>63.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2217126.8</td>\n",
       "      <td>23407.5</td>\n",
       "      <td>402.3</td>\n",
       "      <td>1924.7</td>\n",
       "      <td>18.37</td>\n",
       "      <td>40.769624</td>\n",
       "      <td>-73.968230</td>\n",
       "      <td>8.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>4.135167</td>\n",
       "      <td>4.155753</td>\n",
       "      <td>2.493205</td>\n",
       "      <td>4.768988</td>\n",
       "      <td>7.562525</td>\n",
       "      <td>2.910719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6167</td>\n",
       "      <td>4406956</td>\n",
       "      <td>54030.0</td>\n",
       "      <td>63250.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4716513.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5184.6</td>\n",
       "      <td>81.97</td>\n",
       "      <td>40.847999</td>\n",
       "      <td>-73.940296</td>\n",
       "      <td>12.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>4.335983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.523459</td>\n",
       "      <td>8.553448</td>\n",
       "      <td>4.406353</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10770</td>\n",
       "      <td>4370684</td>\n",
       "      <td>149450.0</td>\n",
       "      <td>149450.0</td>\n",
       "      <td>1934</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>56.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5988399.9</td>\n",
       "      <td>63472.7</td>\n",
       "      <td>136.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.645638</td>\n",
       "      <td>-73.981046</td>\n",
       "      <td>12.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>3.974058</td>\n",
       "      <td>4.032469</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>5.869014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6960</td>\n",
       "      <td>4401878</td>\n",
       "      <td>148827.0</td>\n",
       "      <td>159146.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>74.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8491331.1</td>\n",
       "      <td>92259.8</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.821001</td>\n",
       "      <td>-73.895580</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4.247066</td>\n",
       "      <td>4.306764</td>\n",
       "      <td>1.568616</td>\n",
       "      <td>6.111467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4928</td>\n",
       "      <td>2682511</td>\n",
       "      <td>377823.0</td>\n",
       "      <td>344857.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>78.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>18623690.7</td>\n",
       "      <td>205135.3</td>\n",
       "      <td>747.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.773428</td>\n",
       "      <td>-73.953129</td>\n",
       "      <td>8.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.306764</td>\n",
       "      <td>4.365643</td>\n",
       "      <td>1.856298</td>\n",
       "      <td>6.896897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8272</td>\n",
       "      <td>3114850</td>\n",
       "      <td>72500.0</td>\n",
       "      <td>80475.0</td>\n",
       "      <td>1924</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5252521.5</td>\n",
       "      <td>56063.4</td>\n",
       "      <td>90.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.835794</td>\n",
       "      <td>-73.852112</td>\n",
       "      <td>9.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>4.348987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223775</td>\n",
       "      <td>5.631212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11731</td>\n",
       "      <td>3114772</td>\n",
       "      <td>68076.0</td>\n",
       "      <td>75564.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4101299.9</td>\n",
       "      <td>43882.4</td>\n",
       "      <td>54.9</td>\n",
       "      <td>6365.2</td>\n",
       "      <td>84.24</td>\n",
       "      <td>40.629099</td>\n",
       "      <td>-73.957021</td>\n",
       "      <td>14.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>4.188138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788457</td>\n",
       "      <td>5.477718</td>\n",
       "      <td>8.758601</td>\n",
       "      <td>4.433670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3735</td>\n",
       "      <td>2817479</td>\n",
       "      <td>62237.0</td>\n",
       "      <td>73187.0</td>\n",
       "      <td>1924</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>97.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1814.2</td>\n",
       "      <td>2024.2</td>\n",
       "      <td>26.51</td>\n",
       "      <td>40.756962</td>\n",
       "      <td>-73.976256</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.525044</td>\n",
       "      <td>4.576771</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>-inf</td>\n",
       "      <td>7.612930</td>\n",
       "      <td>3.277522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13808</td>\n",
       "      <td>4404055</td>\n",
       "      <td>53914.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>1929</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>140.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1495400.0</td>\n",
       "      <td>14954.0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>4405.1</td>\n",
       "      <td>81.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>4.945919</td>\n",
       "      <td>1.163151</td>\n",
       "      <td>6.097400</td>\n",
       "      <td>8.390518</td>\n",
       "      <td>4.401584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12447</td>\n",
       "      <td>3782892</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>59.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2934999.7</td>\n",
       "      <td>33086.2</td>\n",
       "      <td>242.2</td>\n",
       "      <td>1310.2</td>\n",
       "      <td>13.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.014580</td>\n",
       "      <td>4.080922</td>\n",
       "      <td>2.028148</td>\n",
       "      <td>5.049215</td>\n",
       "      <td>7.177935</td>\n",
       "      <td>2.572612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4019</td>\n",
       "      <td>2614202</td>\n",
       "      <td>865222.0</td>\n",
       "      <td>863455.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>67.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>475032.0</td>\n",
       "      <td>4750.3</td>\n",
       "      <td>4328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.751983</td>\n",
       "      <td>-73.967538</td>\n",
       "      <td>6.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.169761</td>\n",
       "      <td>4.206184</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>3.226844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14383</td>\n",
       "      <td>2953157</td>\n",
       "      <td>118566.0</td>\n",
       "      <td>144684.0</td>\n",
       "      <td>1963</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>148.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4037400.3</td>\n",
       "      <td>40374.0</td>\n",
       "      <td>306.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.997888</td>\n",
       "      <td>4.997888</td>\n",
       "      <td>1.902108</td>\n",
       "      <td>7.150701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order  Property Id  DOF Gross Floor Area  \\\n",
       "0    4212      4932827              111567.0   \n",
       "1    6167      4406956               54030.0   \n",
       "2   10770      4370684              149450.0   \n",
       "3    6960      4401878              148827.0   \n",
       "4    4928      2682511              377823.0   \n",
       "5    8272      3114850               72500.0   \n",
       "6   11731      3114772               68076.0   \n",
       "7    3735      2817479               62237.0   \n",
       "8   13808      4404055               53914.0   \n",
       "9   12447      3782892              100000.0   \n",
       "10   4019      2614202              865222.0   \n",
       "11  14383      2953157              118566.0   \n",
       "\n",
       "    Largest Property Use Type - Gross Floor Area (ft²)  Year Built  \\\n",
       "0                                             98016.0         1913   \n",
       "1                                             63250.0         1930   \n",
       "2                                            149450.0         1934   \n",
       "3                                            159146.0         1982   \n",
       "4                                            344857.0         1976   \n",
       "5                                             80475.0         1924   \n",
       "6                                             75564.0         1940   \n",
       "7                                             73187.0         1924   \n",
       "8                                             54000.0         1929   \n",
       "9                                            100000.0         1959   \n",
       "10                                           863455.0         2000   \n",
       "11                                           144684.0         1963   \n",
       "\n",
       "    Number of Buildings - Self-reported  Occupancy  \\\n",
       "0                                     1        100   \n",
       "1                                     1        100   \n",
       "2                                     1        100   \n",
       "3                                     1        100   \n",
       "4                                     1        100   \n",
       "5                                     1        100   \n",
       "6                                     1        100   \n",
       "7                                     1        100   \n",
       "8                                     1        100   \n",
       "9                                     1        100   \n",
       "10                                    1        100   \n",
       "11                                    1        100   \n",
       "\n",
       "    Weather Normalized Site EUI (kBtu/ft²)  \\\n",
       "0                                     63.8   \n",
       "1                                      NaN   \n",
       "2                                     56.4   \n",
       "3                                     74.2   \n",
       "4                                     78.7   \n",
       "5                                      NaN   \n",
       "6                                      NaN   \n",
       "7                                     97.2   \n",
       "8                                    140.6   \n",
       "9                                     59.2   \n",
       "10                                    67.1   \n",
       "11                                   148.1   \n",
       "\n",
       "    Weather Normalized Site Electricity Intensity (kWh/ft²)  \\\n",
       "0                                                12.1         \n",
       "1                                                 NaN         \n",
       "2                                                 2.8         \n",
       "3                                                 4.8         \n",
       "4                                                 6.4         \n",
       "5                                                 3.4         \n",
       "6                                                 2.2         \n",
       "7                                                15.0         \n",
       "8                                                 3.2         \n",
       "9                                                 7.6         \n",
       "10                                                8.2         \n",
       "11                                                6.7         \n",
       "\n",
       "    Natural Gas Use (kBtu)  Weather Normalized Site Natural Gas Use (therms)  \\\n",
       "0                2217126.8                                           23407.5   \n",
       "1                4716513.9                                               NaN   \n",
       "2                5988399.9                                           63472.7   \n",
       "3                8491331.1                                           92259.8   \n",
       "4               18623690.7                                          205135.3   \n",
       "5                5252521.5                                           56063.4   \n",
       "6                4101299.9                                           43882.4   \n",
       "7                      NaN                                               NaN   \n",
       "8                1495400.0                                           14954.0   \n",
       "9                2934999.7                                           33086.2   \n",
       "10                475032.0                                            4750.3   \n",
       "11               4037400.3                                           40374.0   \n",
       "\n",
       "    Indirect GHG Emissions (Metric Tons CO2e)  \\\n",
       "0                                       402.3   \n",
       "1                                        11.0   \n",
       "2                                       136.9   \n",
       "3                                       245.0   \n",
       "4                                       747.4   \n",
       "5                                        90.9   \n",
       "6                                        54.9   \n",
       "7                                      1814.2   \n",
       "8                                        57.6   \n",
       "9                                       242.2   \n",
       "10                                     4328.0   \n",
       "11                                      306.6   \n",
       "\n",
       "    Water Use (All Water Sources) (kgal)  \\\n",
       "0                                 1924.7   \n",
       "1                                 5184.6   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "5                                    NaN   \n",
       "6                                 6365.2   \n",
       "7                                 2024.2   \n",
       "8                                 4405.1   \n",
       "9                                 1310.2   \n",
       "10                                   NaN   \n",
       "11                                   NaN   \n",
       "\n",
       "    Water Intensity (All Water Sources) (gal/ft²)   Latitude  Longitude  \\\n",
       "0                                           18.37  40.769624 -73.968230   \n",
       "1                                           81.97  40.847999 -73.940296   \n",
       "2                                             NaN  40.645638 -73.981046   \n",
       "3                                             NaN  40.821001 -73.895580   \n",
       "4                                             NaN  40.773428 -73.953129   \n",
       "5                                             NaN  40.835794 -73.852112   \n",
       "6                                           84.24  40.629099 -73.957021   \n",
       "7                                           26.51  40.756962 -73.976256   \n",
       "8                                           81.58        NaN        NaN   \n",
       "9                                           13.10        NaN        NaN   \n",
       "10                                            NaN  40.751983 -73.967538   \n",
       "11                                            NaN        NaN        NaN   \n",
       "\n",
       "    Community Board  Census Tract  log_Site EUI (kBtu/ft²)  \\\n",
       "0               8.0         122.0                 4.135167   \n",
       "1              12.0         265.0                 4.335983   \n",
       "2              12.0         498.0                 3.974058   \n",
       "3               2.0         159.0                 4.247066   \n",
       "4               8.0         138.0                 4.306764   \n",
       "5               9.0         222.0                 4.348987   \n",
       "6              14.0         772.0                 4.188138   \n",
       "7               5.0          94.0                 4.525044   \n",
       "8               NaN           NaN                 4.859812   \n",
       "9               NaN           NaN                 4.014580   \n",
       "10              6.0          90.0                 4.169761   \n",
       "11              NaN           NaN                 4.997888   \n",
       "\n",
       "    log_Weather Normalized Site EUI (kBtu/ft²)  \\\n",
       "0                                     4.155753   \n",
       "1                                          NaN   \n",
       "2                                     4.032469   \n",
       "3                                     4.306764   \n",
       "4                                     4.365643   \n",
       "5                                          NaN   \n",
       "6                                          NaN   \n",
       "7                                     4.576771   \n",
       "8                                     4.945919   \n",
       "9                                     4.080922   \n",
       "10                                    4.206184   \n",
       "11                                    4.997888   \n",
       "\n",
       "    log_Weather Normalized Site Electricity Intensity (kWh/ft²)  \\\n",
       "0                                            2.493205             \n",
       "1                                                 NaN             \n",
       "2                                            1.029619             \n",
       "3                                            1.568616             \n",
       "4                                            1.856298             \n",
       "5                                            1.223775             \n",
       "6                                            0.788457             \n",
       "7                                            2.708050             \n",
       "8                                            1.163151             \n",
       "9                                            2.028148             \n",
       "10                                           2.104134             \n",
       "11                                           1.902108             \n",
       "\n",
       "    log_Direct GHG Emissions (Metric Tons CO2e)  \\\n",
       "0                                      4.768988   \n",
       "1                                      5.523459   \n",
       "2                                      5.869014   \n",
       "3                                      6.111467   \n",
       "4                                      6.896897   \n",
       "5                                      5.631212   \n",
       "6                                      5.477718   \n",
       "7                                          -inf   \n",
       "8                                      6.097400   \n",
       "9                                      5.049215   \n",
       "10                                     3.226844   \n",
       "11                                     7.150701   \n",
       "\n",
       "    log_Water Use (All Water Sources) (kgal)  \\\n",
       "0                                   7.562525   \n",
       "1                                   8.553448   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "5                                        NaN   \n",
       "6                                   8.758601   \n",
       "7                                   7.612930   \n",
       "8                                   8.390518   \n",
       "9                                   7.177935   \n",
       "10                                       NaN   \n",
       "11                                       NaN   \n",
       "\n",
       "    log_Water Intensity (All Water Sources) (gal/ft²)  Borough_Staten Island  \\\n",
       "0                                            2.910719                      0   \n",
       "1                                            4.406353                      0   \n",
       "2                                                 NaN                      0   \n",
       "3                                                 NaN                      0   \n",
       "4                                                 NaN                      0   \n",
       "5                                                 NaN                      0   \n",
       "6                                            4.433670                      0   \n",
       "7                                            3.277522                      0   \n",
       "8                                            4.401584                      0   \n",
       "9                                            2.572612                      0   \n",
       "10                                                NaN                      0   \n",
       "11                                                NaN                      0   \n",
       "\n",
       "    Largest Property Use Type_Adult Education  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "8                                           0   \n",
       "9                                           0   \n",
       "10                                          0   \n",
       "11                                          0   \n",
       "\n",
       "    Largest Property Use Type_Ambulatory Surgical Center  \\\n",
       "0                                                   0      \n",
       "1                                                   0      \n",
       "2                                                   0      \n",
       "3                                                   0      \n",
       "4                                                   0      \n",
       "5                                                   0      \n",
       "6                                                   0      \n",
       "7                                                   0      \n",
       "8                                                   0      \n",
       "9                                                   0      \n",
       "10                                                  0      \n",
       "11                                                  0      \n",
       "\n",
       "    Largest Property Use Type_Automobile Dealership  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "5                                                 0   \n",
       "6                                                 0   \n",
       "7                                                 0   \n",
       "8                                                 0   \n",
       "9                                                 0   \n",
       "10                                                0   \n",
       "11                                                0   \n",
       "\n",
       "    Largest Property Use Type_Bank Branch  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "5                                       0   \n",
       "6                                       0   \n",
       "7                                       0   \n",
       "8                                       0   \n",
       "9                                       0   \n",
       "10                                      0   \n",
       "11                                      0   \n",
       "\n",
       "    Largest Property Use Type_College/University  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "5                                              0   \n",
       "6                                              0   \n",
       "7                                              0   \n",
       "8                                              0   \n",
       "9                                              0   \n",
       "10                                             0   \n",
       "11                                             0   \n",
       "\n",
       "                       ...                      \\\n",
       "0                      ...                       \n",
       "1                      ...                       \n",
       "2                      ...                       \n",
       "3                      ...                       \n",
       "4                      ...                       \n",
       "5                      ...                       \n",
       "6                      ...                       \n",
       "7                      ...                       \n",
       "8                      ...                       \n",
       "9                      ...                       \n",
       "10                     ...                       \n",
       "11                     ...                       \n",
       "\n",
       "    Largest Property Use Type_Museum  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "5                                  0   \n",
       "6                                  0   \n",
       "7                                  0   \n",
       "8                                  0   \n",
       "9                                  0   \n",
       "10                                 0   \n",
       "11                                 0   \n",
       "\n",
       "    Largest Property Use Type_Non-Refrigerated Warehouse  \\\n",
       "0                                                   0      \n",
       "1                                                   0      \n",
       "2                                                   0      \n",
       "3                                                   0      \n",
       "4                                                   0      \n",
       "5                                                   0      \n",
       "6                                                   0      \n",
       "7                                                   0      \n",
       "8                                                   0      \n",
       "9                                                   1      \n",
       "10                                                  0      \n",
       "11                                                  0      \n",
       "\n",
       "    Largest Property Use Type_Other  \\\n",
       "0                                 0   \n",
       "1                                 0   \n",
       "2                                 0   \n",
       "3                                 0   \n",
       "4                                 0   \n",
       "5                                 0   \n",
       "6                                 0   \n",
       "7                                 0   \n",
       "8                                 0   \n",
       "9                                 0   \n",
       "10                                0   \n",
       "11                                0   \n",
       "\n",
       "    Largest Property Use Type_Other - Education  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "5                                             0   \n",
       "6                                             0   \n",
       "7                                             0   \n",
       "8                                             0   \n",
       "9                                             0   \n",
       "10                                            0   \n",
       "11                                            0   \n",
       "\n",
       "    Largest Property Use Type_Other - Entertainment/Public Assembly  \\\n",
       "0                                                   0                 \n",
       "1                                                   0                 \n",
       "2                                                   0                 \n",
       "3                                                   0                 \n",
       "4                                                   0                 \n",
       "5                                                   0                 \n",
       "6                                                   0                 \n",
       "7                                                   0                 \n",
       "8                                                   0                 \n",
       "9                                                   0                 \n",
       "10                                                  0                 \n",
       "11                                                  0                 \n",
       "\n",
       "    Largest Property Use Type_Other - Lodging/Residential  \\\n",
       "0                                                   0       \n",
       "1                                                   0       \n",
       "2                                                   0       \n",
       "3                                                   0       \n",
       "4                                                   0       \n",
       "5                                                   0       \n",
       "6                                                   0       \n",
       "7                                                   0       \n",
       "8                                                   0       \n",
       "9                                                   0       \n",
       "10                                                  0       \n",
       "11                                                  0       \n",
       "\n",
       "    Largest Property Use Type_Other - Mall  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "11                                       0   \n",
       "\n",
       "    Largest Property Use Type_Other - Public Services  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "5                                                   0   \n",
       "6                                                   0   \n",
       "7                                                   0   \n",
       "8                                                   0   \n",
       "9                                                   0   \n",
       "10                                                  0   \n",
       "11                                                  0   \n",
       "\n",
       "    Largest Property Use Type_Other - Recreation  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "5                                              0   \n",
       "6                                              0   \n",
       "7                                              0   \n",
       "8                                              0   \n",
       "9                                              0   \n",
       "10                                             0   \n",
       "11                                             0   \n",
       "\n",
       "    Largest Property Use Type_Other - Services  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "5                                            0   \n",
       "6                                            0   \n",
       "7                                            0   \n",
       "8                                            0   \n",
       "9                                            0   \n",
       "10                                           0   \n",
       "11                                           0   \n",
       "\n",
       "    Largest Property Use Type_Other - Specialty Hospital  \\\n",
       "0                                                   0      \n",
       "1                                                   0      \n",
       "2                                                   0      \n",
       "3                                                   0      \n",
       "4                                                   0      \n",
       "5                                                   0      \n",
       "6                                                   0      \n",
       "7                                                   0      \n",
       "8                                                   0      \n",
       "9                                                   0      \n",
       "10                                                  0      \n",
       "11                                                  0      \n",
       "\n",
       "    Largest Property Use Type_Other - Technology/Science  \\\n",
       "0                                                   0      \n",
       "1                                                   0      \n",
       "2                                                   0      \n",
       "3                                                   0      \n",
       "4                                                   0      \n",
       "5                                                   0      \n",
       "6                                                   0      \n",
       "7                                                   0      \n",
       "8                                                   0      \n",
       "9                                                   0      \n",
       "10                                                  0      \n",
       "11                                                  0      \n",
       "\n",
       "    Largest Property Use Type_Outpatient Rehabilitation/Physical Therapy  \\\n",
       "0                                                   0                      \n",
       "1                                                   0                      \n",
       "2                                                   0                      \n",
       "3                                                   0                      \n",
       "4                                                   0                      \n",
       "5                                                   0                      \n",
       "6                                                   0                      \n",
       "7                                                   0                      \n",
       "8                                                   0                      \n",
       "9                                                   0                      \n",
       "10                                                  0                      \n",
       "11                                                  0                      \n",
       "\n",
       "    Largest Property Use Type_Parking  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "5                                   0   \n",
       "6                                   0   \n",
       "7                                   0   \n",
       "8                                   0   \n",
       "9                                   0   \n",
       "10                                  0   \n",
       "11                                  0   \n",
       "\n",
       "    Largest Property Use Type_Performing Arts  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "8                                           0   \n",
       "9                                           0   \n",
       "10                                          0   \n",
       "11                                          0   \n",
       "\n",
       "    Largest Property Use Type_Pre-school/Daycare  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "5                                              0   \n",
       "6                                              0   \n",
       "7                                              0   \n",
       "8                                              0   \n",
       "9                                              0   \n",
       "10                                             0   \n",
       "11                                             0   \n",
       "\n",
       "    Largest Property Use Type_Refrigerated Warehouse  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "5                                                  0   \n",
       "6                                                  0   \n",
       "7                                                  0   \n",
       "8                                                  0   \n",
       "9                                                  0   \n",
       "10                                                 0   \n",
       "11                                                 0   \n",
       "\n",
       "    Largest Property Use Type_Repair Services (Vehicle, Shoe, Locksmith, etc.)  \\\n",
       "0                                                   0                            \n",
       "1                                                   0                            \n",
       "2                                                   0                            \n",
       "3                                                   0                            \n",
       "4                                                   0                            \n",
       "5                                                   0                            \n",
       "6                                                   0                            \n",
       "7                                                   0                            \n",
       "8                                                   0                            \n",
       "9                                                   0                            \n",
       "10                                                  0                            \n",
       "11                                                  0                            \n",
       "\n",
       "    Largest Property Use Type_Residence Hall/Dormitory  \\\n",
       "0                                                   0    \n",
       "1                                                   0    \n",
       "2                                                   0    \n",
       "3                                                   0    \n",
       "4                                                   0    \n",
       "5                                                   0    \n",
       "6                                                   0    \n",
       "7                                                   0    \n",
       "8                                                   0    \n",
       "9                                                   0    \n",
       "10                                                  0    \n",
       "11                                                  0    \n",
       "\n",
       "    Largest Property Use Type_Residential Care Facility  \\\n",
       "0                                                   0     \n",
       "1                                                   0     \n",
       "2                                                   0     \n",
       "3                                                   0     \n",
       "4                                                   0     \n",
       "5                                                   0     \n",
       "6                                                   0     \n",
       "7                                                   0     \n",
       "8                                                   0     \n",
       "9                                                   0     \n",
       "10                                                  0     \n",
       "11                                                  0     \n",
       "\n",
       "    Largest Property Use Type_Restaurant  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "5                                      0   \n",
       "6                                      0   \n",
       "7                                      0   \n",
       "8                                      0   \n",
       "9                                      0   \n",
       "10                                     0   \n",
       "11                                     0   \n",
       "\n",
       "    Largest Property Use Type_Retail Store  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        0   \n",
       "9                                        0   \n",
       "10                                       0   \n",
       "11                                       0   \n",
       "\n",
       "    Largest Property Use Type_Self-Storage Facility  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "5                                                 0   \n",
       "6                                                 0   \n",
       "7                                                 0   \n",
       "8                                                 0   \n",
       "9                                                 0   \n",
       "10                                                0   \n",
       "11                                                0   \n",
       "\n",
       "    Largest Property Use Type_Senior Care Community  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "5                                                 0   \n",
       "6                                                 0   \n",
       "7                                                 0   \n",
       "8                                                 0   \n",
       "9                                                 0   \n",
       "10                                                0   \n",
       "11                                                0   \n",
       "\n",
       "    Largest Property Use Type_Social/Meeting Hall  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               0   \n",
       "8                                               0   \n",
       "9                                               0   \n",
       "10                                              0   \n",
       "11                                              0   \n",
       "\n",
       "    Largest Property Use Type_Strip Mall  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "4                                      0   \n",
       "5                                      0   \n",
       "6                                      0   \n",
       "7                                      0   \n",
       "8                                      0   \n",
       "9                                      0   \n",
       "10                                     0   \n",
       "11                                     0   \n",
       "\n",
       "    Largest Property Use Type_Supermarket/Grocery Store  \\\n",
       "0                                                   0     \n",
       "1                                                   0     \n",
       "2                                                   0     \n",
       "3                                                   0     \n",
       "4                                                   0     \n",
       "5                                                   0     \n",
       "6                                                   0     \n",
       "7                                                   0     \n",
       "8                                                   0     \n",
       "9                                                   0     \n",
       "10                                                  0     \n",
       "11                                                  0     \n",
       "\n",
       "    Largest Property Use Type_Urgent Care/Clinic/Other Outpatient  \\\n",
       "0                                                   0               \n",
       "1                                                   0               \n",
       "2                                                   0               \n",
       "3                                                   0               \n",
       "4                                                   0               \n",
       "5                                                   0               \n",
       "6                                                   0               \n",
       "7                                                   0               \n",
       "8                                                   0               \n",
       "9                                                   0               \n",
       "10                                                  0               \n",
       "11                                                  0               \n",
       "\n",
       "    Largest Property Use Type_Wholesale Club/Supercenter  \\\n",
       "0                                                   0      \n",
       "1                                                   0      \n",
       "2                                                   0      \n",
       "3                                                   0      \n",
       "4                                                   0      \n",
       "5                                                   0      \n",
       "6                                                   0      \n",
       "7                                                   0      \n",
       "8                                                   0      \n",
       "9                                                   0      \n",
       "10                                                  0      \n",
       "11                                                  0      \n",
       "\n",
       "    Largest Property Use Type_Worship Facility  \n",
       "0                                            0  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "5                                            0  \n",
       "6                                            0  \n",
       "7                                            0  \n",
       "8                                            0  \n",
       "9                                            0  \n",
       "10                                           0  \n",
       "11                                           0  \n",
       "\n",
       "[12 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save features for later interpretation\n",
    "features = X.columns\n",
    "\n",
    "X.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Comparing Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are missing values in a number of columns. Although we dropped features with more than 50% missing values, there are still quite a few left that must be addressed before we do machine learning. There are a number of methods for filling in missing values (known as imputation) but here we will use the relatively simple method of replacing missing values with the median of the column. In the code below, we create a scikit-learn `Imputer` object and then fill in the missing values.\n",
    "\n",
    "Notice that we train the imputer (using the `.fit` method) on the training data but not the testing data. We then transform both the training data and testing data. This means that the missing values in the testing set are filled in with the median value of the corresponding columns in the training set. We have to do it this way rather than training on all the data because at production time, we will have to impute the missing values based on the previous training data and not on any new observations we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all problem values are recorded as np.nan\n",
    "X = X.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "X_test = X_test.replace({np.inf: np.nan, -np.inf: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object with a median filling strategy\n",
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "# Train on the training features\n",
    "imputer.fit(X)\n",
    "\n",
    "# Transform both training data and testing data\n",
    "X = imputer.transform(X)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training features:  0\n",
      "Missing values in testing features:   0\n"
     ]
    }
   ],
   "source": [
    "print('Missing values in training features: ', np.sum(np.isnan(X)))\n",
    "print('Missing values in testing features:  ', np.sum(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Make sure all values are finite\n",
    "print(np.where(~np.isfinite(X)))\n",
    "print(np.where(~np.isfinite(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Features\n",
    "\n",
    "The final step to take before we can get to machine learning is to scale the features between 0 and 1. This is necessary because features are in different units, and we want to normalize the features so the units do not affect the algorithm. Linear Regression and Random Forest do not require feature scaling, but other methods, such as support vector machines and k nearest neighbors, do require it and so it is a best practice to scale all of the features before training a machine learning model. \n",
    "\n",
    "There are two ways to scale features:\n",
    "\n",
    "1. Subtract the mean and divide by the standard deviation. This is often called standardization and results in each feature having a mean of 0 and a standard deviation of 1.\n",
    "2. Subtract the minimum value from each feature value and divide by the maximum minus the minimum for the feature (the range of the feature). This assures that all the values for a feature are between 0 and 1.\n",
    "\n",
    "As with imputation, when we train the scaling object, we want to use only the training set. When we transform features, we will transform both the training set and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to remind ourselves, here is the naive baseline performance measured in mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Performance on the test set: MAE = 25.3519\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate mean absolute error\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))\n",
    "\n",
    "baseline_guess = np.median(y)\n",
    "print(\"Baseline Performance on the test set: MAE = %0.4f\" % mae(y_test, baseline_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models to Evaluate\n",
    "\n",
    "We will compare five different models:\n",
    "\n",
    "1. Linear Regression\n",
    "2. Support Vector Machine Regression\n",
    "3. Random Forest Regression\n",
    "4. Gradient Boosting Regression\n",
    "5. K-Nearest Neighbors Regression\n",
    "\n",
    "To evaluate the models, we are going to be using the sklearn defaults for the model hyperparameters. Generally these will perform decent, but should be optimized before actually using a model. Now we just want to determine the baseline performance of each model, and then we can select the best-performer for further optimization. I don't want to get bogged down in the model theory or hyperparameters, so I'll leave it up to you to do some research. Just know that the default hyperparameters will get a model up and running, but nearly always should be adjusted using some sort of search to find the best settings for your problem.\n",
    "\n",
    "One of the best parts about scikit-learn is that all models are implemented in basically the same manner: once you know how to build one, you can implement an extremely diverse array of models. Here we will implement the entire training and testing procedures for a number of models in just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn wants the labels as one-dimensional vectors\n",
    "y = np.array(y).reshape((-1,))\n",
    "y_test = np.array(y_test).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model):\n",
    "    model.fit(X, y)\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_mae = mae(y_test, model_pred)\n",
    "    \n",
    "    return model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance on the test set: MAE = 16.7341\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "print('Linear Regression Performance on the test set: MAE = %0.4f' % fit_and_evaluate(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression Performance on the test set: MAE = 14.1151\n"
     ]
    }
   ],
   "source": [
    "svm = SVR(C = 1000, gamma = 0.1)\n",
    "print('Support Vector Regression Performance on the test set: MAE = %0.4f' % fit_and_evaluate(svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Performance on the test set: MAE = 9.8451\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor()\n",
    "print('Random Forest Regression Performance on the test set: MAE = %0.4f' % fit_and_evaluate(random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Regression Performance on the test set: MAE = 10.0622\n"
     ]
    }
   ],
   "source": [
    "gradient_boosted = GradientBoostingRegressor()\n",
    "print('Gradient Boosted Regression Performance on the test set: MAE = %0.4f' % fit_and_evaluate(gradient_boosted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regression Performance on the test set: MAE = 17.4093\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "print('K-Nearest Neighbors Regression Performance on the test set: MAE = %0.4f' % fit_and_evaluate(knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest does the best with the Gradient Boosted Regression coming in second. This is not the best comparison because we are using the default hyperparameters, and especially with the Support Vector Regressor, the hyperparameters have a significnant influence on performance. Nonetheless, we can conclude that machine learning is applicable because the random forest model significantly outperforms the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Best Model\n",
    "\n",
    "Model __hyperparameters__ are best thought of as tunable settings for a machine learning algorithm that are set by the data scientist ahead to training time. An example would be the number of trees in the random forest, or the number of neighbors used in K Nearest Neighbors Regression. Model __parameters__ on the other hand are what the model learns during training, such as the weights in the linear regression or the exact structure of each decision tree. We as data scientists control the model by choosing the hyperparameters, and these choices can have a significant effect on the final performance of the model (although usually not as great of an effect as getting more data or engineering features). \n",
    "\n",
    "Generally, we adjust the model hyperparameters to control the amount of under or over fitting in our model. We can correct for under-fitting by making a more complex model, such as using more trees in a random forest or more layers in a deep neural network. A model that underfits has high bias, and occurs when our model does not have enough capacity or degrees of freedom to learn the relationship between the features and the target. We can try to correct for overfitting by limiting the complexity of the model and applying regularization. This might mean decreasing the degree of a polynomial regression, or adding dropout layers to a deep neural network. A model that overfits has high variance and in effect has memorized the training set. Both underfitting and overfitting lead to poor generalization performance on the test set. \n",
    "\n",
    "## Hyperparameter Tuning with Random Search and Cross Validation\n",
    "\n",
    "We can choose the best hyperparameters for a model through random search and cross validation. Random search refers to the method in which we choose hyperparameters to evaluate: we define a range of options, and then randomly select combinations to try. This is in contrast to grid search which evaluates every single combination we specify. Generally, random search is better when we have limited knowledge of the best model hyperparameters and we can use random search to narrow down the options and then use grid search with a more limited range of options. Cross validation is the method used to assess the performance of the hyperparameters. Rather than splitting the training set up into separate training and validation sets which reduces the amount of training data we can use, we use K-Fold Cross Validation. This means dividing the training data into K folds, and then going through an iterative process where we first train on K-1 of the folds and then evaluate performance on the kth fold. We repeat this process K times so eventually we will have tested on every example in the training data with the key that each iteration we are testing on data that we __did not train on__.  At the end of K-fold cross validation, we take the average error on each of the K iterations as the final performance measure and then train the model on all the training data at once. The performance we record is then used to compare different combinations of hyperparameters. \n",
    "\n",
    "Here we will implement random search with cross validation to select the optimal hyperparameters for the random forest. We first define a grid and then iteratively randomly sample a set of hyperparameters from the grid, evaluate the hyperparameters using 4-fold cross-validation, and then select the hyperparameters with the best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in the forest\n",
    "n_estimators = [100, 200, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "# Maximum depth of each tree\n",
    "max_depth = [None, 10, 20, 30, 40, 50, 60]\n",
    "\n",
    "# Minimum number of samples per leaf\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "# Maximum number of features to consider for making splits\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected 4 different hyperparameters to tune in the random forest. These all will affect the model in different ways that are hard to determine ahead of time, and the only method for finding the best combination for a specific problem is to test them out! To read about the hyperparameters, I suggest taking a look at the scikit-learn documentation for the random forest. For now, just know that we are trying to find the best combination of hyperparameters and because there is no theory to tell us which will work best, we just have to evaluate them, sort of like runnning an experiment.\n",
    "\n",
    "\n",
    "In the code below, we create the Randomized Search Object passing in the following parameters:\n",
    "\n",
    "* `estimator`: the model\n",
    "* `param_distributions`: the distribution of parameters we defined\n",
    "* `cv` the number of folds to use for k-fold cross validation\n",
    "* `n_iter`: the number of different combinations to try\n",
    "* `scoring`: which metric to use when evaluating candidates\n",
    "* `n_jobs`: number of cores to run in parallel (-1 will use all available)\n",
    "* `verbose`: how much information to display (1 displays a limited amount) \n",
    "* `return_train_score`: return the training score for each cross-validation fold\n",
    "* `random_state`: fixes the random number generator used so we get the same results every run\n",
    "\n",
    "The Randomized Search Object is trained the same way as any other scikit-learn model. After training, we can evaluate all the different hyperparameter combinations and find the best performing one. This can then be used to perform grid search, or we can just use these settings as the final ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to use for hyperparameter tuning\n",
    "model = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(model, param_distributions=hyperparameter_grid,\n",
    "                               cv=4, n_iter=25, scoring = 'neg_mean_absolute_error',\n",
    "                               n_jobs = -1, verbose = 1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=25, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800], 'max_depth': [None, 10, 20, 30, 40, 50, 60], 'min_samples_leaf': [1, 2, 4, 6, 8], 'max_features': ['auto', 'sqrt', 'log2', None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on the training data\n",
    "random_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn uses the negative mean absolute error for evaluation because it wants a metric to maximize. Therefore, a better score will be closer to 0. We can get the results of the randomized search into a dataframe, and sort the values by performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.182980</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>-9.093136</td>\n",
       "      <td>-3.384145</td>\n",
       "      <td>60</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>{'n_estimators': 400, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.400874</td>\n",
       "      <td>-3.370514</td>\n",
       "      <td>-8.816949</td>\n",
       "      <td>-3.406770</td>\n",
       "      <td>-9.231566</td>\n",
       "      <td>-3.359313</td>\n",
       "      <td>-8.922971</td>\n",
       "      <td>-3.399985</td>\n",
       "      <td>0.142482</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.234054</td>\n",
       "      <td>0.019782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.007573</td>\n",
       "      <td>0.131099</td>\n",
       "      <td>-9.098269</td>\n",
       "      <td>-3.401847</td>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.420741</td>\n",
       "      <td>-3.388466</td>\n",
       "      <td>-8.817958</td>\n",
       "      <td>-3.418074</td>\n",
       "      <td>-9.236485</td>\n",
       "      <td>-3.374752</td>\n",
       "      <td>-8.917703</td>\n",
       "      <td>-3.426097</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.242021</td>\n",
       "      <td>0.021003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.682472</td>\n",
       "      <td>0.148145</td>\n",
       "      <td>-9.098351</td>\n",
       "      <td>-3.402665</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.420231</td>\n",
       "      <td>-3.388048</td>\n",
       "      <td>-8.814213</td>\n",
       "      <td>-3.418456</td>\n",
       "      <td>-9.243106</td>\n",
       "      <td>-3.376721</td>\n",
       "      <td>-8.915661</td>\n",
       "      <td>-3.427437</td>\n",
       "      <td>0.169498</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.244283</td>\n",
       "      <td>0.020915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.575539</td>\n",
       "      <td>0.057151</td>\n",
       "      <td>-9.108879</td>\n",
       "      <td>-3.931810</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_leaf': 2, '...</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.399846</td>\n",
       "      <td>-3.929285</td>\n",
       "      <td>-8.836594</td>\n",
       "      <td>-3.953931</td>\n",
       "      <td>-9.284826</td>\n",
       "      <td>-3.901245</td>\n",
       "      <td>-8.914079</td>\n",
       "      <td>-3.942780</td>\n",
       "      <td>0.085163</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.238601</td>\n",
       "      <td>0.019687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.604852</td>\n",
       "      <td>0.262448</td>\n",
       "      <td>-9.177524</td>\n",
       "      <td>-5.220312</td>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_leaf': 4, '...</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.455321</td>\n",
       "      <td>-5.217603</td>\n",
       "      <td>-8.857832</td>\n",
       "      <td>-5.253102</td>\n",
       "      <td>-9.381737</td>\n",
       "      <td>-5.180702</td>\n",
       "      <td>-9.015041</td>\n",
       "      <td>-5.229840</td>\n",
       "      <td>0.275127</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>0.026183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51.609525</td>\n",
       "      <td>0.265708</td>\n",
       "      <td>-9.177524</td>\n",
       "      <td>-5.220312</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_leaf': 4, '...</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.455321</td>\n",
       "      <td>-5.217603</td>\n",
       "      <td>-8.857832</td>\n",
       "      <td>-5.253102</td>\n",
       "      <td>-9.381737</td>\n",
       "      <td>-5.180702</td>\n",
       "      <td>-9.015041</td>\n",
       "      <td>-5.229840</td>\n",
       "      <td>0.233738</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>0.026183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.788284</td>\n",
       "      <td>0.041361</td>\n",
       "      <td>-9.203500</td>\n",
       "      <td>-5.242076</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_leaf': 4, '...</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.437459</td>\n",
       "      <td>-5.241582</td>\n",
       "      <td>-8.916676</td>\n",
       "      <td>-5.259685</td>\n",
       "      <td>-9.398743</td>\n",
       "      <td>-5.212892</td>\n",
       "      <td>-9.060983</td>\n",
       "      <td>-5.254145</td>\n",
       "      <td>0.049178</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.221043</td>\n",
       "      <td>0.018081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.755788</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>-9.246512</td>\n",
       "      <td>-6.397655</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_leaf': 4, '...</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.501874</td>\n",
       "      <td>-6.404307</td>\n",
       "      <td>-8.966531</td>\n",
       "      <td>-6.443215</td>\n",
       "      <td>-9.427680</td>\n",
       "      <td>-6.327673</td>\n",
       "      <td>-9.089812</td>\n",
       "      <td>-6.415423</td>\n",
       "      <td>0.048297</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.224157</td>\n",
       "      <td>0.042817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64.111023</td>\n",
       "      <td>0.234132</td>\n",
       "      <td>-9.296568</td>\n",
       "      <td>-6.212067</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>6</td>\n",
       "      <td>800</td>\n",
       "      <td>{'n_estimators': 800, 'min_samples_leaf': 6, '...</td>\n",
       "      <td>9</td>\n",
       "      <td>-9.584369</td>\n",
       "      <td>-6.208052</td>\n",
       "      <td>-8.935978</td>\n",
       "      <td>-6.260123</td>\n",
       "      <td>-9.489070</td>\n",
       "      <td>-6.169388</td>\n",
       "      <td>-9.176685</td>\n",
       "      <td>-6.210704</td>\n",
       "      <td>0.315609</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.341449</td>\n",
       "      <td>0.247910</td>\n",
       "      <td>-9.297432</td>\n",
       "      <td>-6.215743</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>{'n_estimators': 600, 'min_samples_leaf': 6, '...</td>\n",
       "      <td>10</td>\n",
       "      <td>-9.589846</td>\n",
       "      <td>-6.206113</td>\n",
       "      <td>-8.942439</td>\n",
       "      <td>-6.262485</td>\n",
       "      <td>-9.486806</td>\n",
       "      <td>-6.177121</td>\n",
       "      <td>-9.170464</td>\n",
       "      <td>-6.217253</td>\n",
       "      <td>0.224911</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.256672</td>\n",
       "      <td>0.030706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "2       50.182980         0.257937        -9.093136         -3.384145   \n",
       "19      27.007573         0.131099        -9.098269         -3.401847   \n",
       "13      26.682472         0.148145        -9.098351         -3.402665   \n",
       "8       11.575539         0.057151        -9.108879         -3.931810   \n",
       "6       50.604852         0.262448        -9.177524         -5.220312   \n",
       "15      51.609525         0.265708        -9.177524         -5.220312   \n",
       "5        9.788284         0.041361        -9.203500         -5.242076   \n",
       "9        8.755788         0.041863        -9.246512         -6.397655   \n",
       "22      64.111023         0.234132        -9.296568         -6.212067   \n",
       "14      55.341449         0.247910        -9.297432         -6.215743   \n",
       "\n",
       "   param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "2               60               auto                      1   \n",
       "19              40               None                      1   \n",
       "13              30               auto                      1   \n",
       "8             None               None                      2   \n",
       "6               40               auto                      4   \n",
       "15              30               None                      4   \n",
       "5               50               None                      4   \n",
       "9               10               None                      4   \n",
       "22              20               auto                      6   \n",
       "14              60               None                      6   \n",
       "\n",
       "   param_n_estimators                                             params  \\\n",
       "2                 400  {'n_estimators': 400, 'min_samples_leaf': 1, '...   \n",
       "19                200  {'n_estimators': 200, 'min_samples_leaf': 1, '...   \n",
       "13                200  {'n_estimators': 200, 'min_samples_leaf': 1, '...   \n",
       "8                 100  {'n_estimators': 100, 'min_samples_leaf': 2, '...   \n",
       "6                 500  {'n_estimators': 500, 'min_samples_leaf': 4, '...   \n",
       "15                500  {'n_estimators': 500, 'min_samples_leaf': 4, '...   \n",
       "5                 100  {'n_estimators': 100, 'min_samples_leaf': 4, '...   \n",
       "9                 100  {'n_estimators': 100, 'min_samples_leaf': 4, '...   \n",
       "22                800  {'n_estimators': 800, 'min_samples_leaf': 6, '...   \n",
       "14                600  {'n_estimators': 600, 'min_samples_leaf': 6, '...   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "2                 1          -9.400874           -3.370514          -8.816949   \n",
       "19                2          -9.420741           -3.388466          -8.817958   \n",
       "13                3          -9.420231           -3.388048          -8.814213   \n",
       "8                 4          -9.399846           -3.929285          -8.836594   \n",
       "6                 5          -9.455321           -5.217603          -8.857832   \n",
       "15                5          -9.455321           -5.217603          -8.857832   \n",
       "5                 7          -9.437459           -5.241582          -8.916676   \n",
       "9                 8          -9.501874           -6.404307          -8.966531   \n",
       "22                9          -9.584369           -6.208052          -8.935978   \n",
       "14               10          -9.589846           -6.206113          -8.942439   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  \\\n",
       "2            -3.406770          -9.231566           -3.359313   \n",
       "19           -3.418074          -9.236485           -3.374752   \n",
       "13           -3.418456          -9.243106           -3.376721   \n",
       "8            -3.953931          -9.284826           -3.901245   \n",
       "6            -5.253102          -9.381737           -5.180702   \n",
       "15           -5.253102          -9.381737           -5.180702   \n",
       "5            -5.259685          -9.398743           -5.212892   \n",
       "9            -6.443215          -9.427680           -6.327673   \n",
       "22           -6.260123          -9.489070           -6.169388   \n",
       "14           -6.262485          -9.486806           -6.177121   \n",
       "\n",
       "    split3_test_score  split3_train_score  std_fit_time  std_score_time  \\\n",
       "2           -8.922971           -3.399985      0.142482        0.014793   \n",
       "19          -8.917703           -3.426097      0.055266        0.010667   \n",
       "13          -8.915661           -3.427437      0.169498        0.005324   \n",
       "8           -8.914079           -3.942780      0.085163        0.004963   \n",
       "6           -9.015041           -5.229840      0.275127        0.017213   \n",
       "15          -9.015041           -5.229840      0.233738        0.009159   \n",
       "5           -9.060983           -5.254145      0.049178        0.000434   \n",
       "9           -9.089812           -6.415423      0.048297        0.010011   \n",
       "22          -9.176685           -6.210704      0.315609        0.001679   \n",
       "14          -9.170464           -6.217253      0.224911        0.012185   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "2         0.234054         0.019782  \n",
       "19        0.242021         0.021003  \n",
       "13        0.244283         0.020915  \n",
       "8         0.238601         0.019687  \n",
       "6         0.248740         0.026183  \n",
       "15        0.248740         0.026183  \n",
       "5         0.221043         0.018081  \n",
       "9         0.224157         0.042817  \n",
       "22        0.257047         0.032206  \n",
       "14        0.256672         0.030706  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all of the cv results and sort by the test performance\n",
    "random_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "\n",
    "random_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the best model has the following hyperparameters:\n",
    "\n",
    "* `n_estimators = 400`\n",
    "* `min_samples_leaf = 1`\n",
    "* `max_depth = 60`\n",
    "* `max_features = auto` (This means that `max_features = n_features` according to the docs)\n",
    "\n",
    "Now, we can further try to optimize by focusing on a narrower range of hyperparameters tat were seen to work best during the random search. We could do this by setting up a grid with hyperparameters very close to those that worked best during the randomized search. However, rather than evaluating all of these settings again, I will focus on a single one, the number of trees in the forest (`n_estimators`). By varying only one hyperparameter, we can directly observe how it affects performance. In the case of the number of trees, this should have significant impact on the amount of underfitting or overfitting. \n",
    "\n",
    "To determine the effect on the model of the number of trees, we can use grid search with a grid that only has the `n_estimators` hyperparameter. We can try out a range of trees and then plot the training and testing performance to get an idea of what increasing the number of trees does for our model. We will fix the other hyperparameters at the best values return from random search to isolate the number of trees effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of trees to evaluate\n",
    "trees_grid = {'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600]}\n",
    "\n",
    "model = RandomForestRegressor(min_samples_leaf = 1, max_depth = 60,\n",
    "                              max_features = 'auto', random_state = 42,\n",
    "                              n_jobs = -1)\n",
    "\n",
    "# Grid Search Object using the trees range and the random forest model\n",
    "grid_search = GridSearchCV(model, param_grid=trees_grid, cv = 4, \n",
    "                          scoring = 'neg_mean_absolute_error', verbose = 1, \n",
    "                          n_jobs = -1, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=60,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Performance vs Number of Trees')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dd012c6860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the results into a dataframe\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Plot the training and testing error vs number of trees\n",
    "figsize(8, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(results['param_n_estimators'], -1 * results['mean_test_score'], label = 'Testing Error')\n",
    "plt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Training Error')\n",
    "plt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend();\n",
    "plt.title('Performance vs Number of Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, it's pretty clear our model is overfitting! The training error is significantly lower than the testing error, which shows that the model is memorizing the training data but then is not able to generalize well to the testing data. There are a number of ways we can try to correct this in a random forest, such as increasing the minimum number of samples at a leaf node.  but for now, we will use the best performing model on the test set and try to interpret the results. If you want, feel free to attempt to reduce the amount of overfitting so the model generalizes better to the testing set! \n",
    "\n",
    "Let's select the best model and implement it to make final predictions for the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Final Model on the Test Set\n",
    "\n",
    "We will use the best model from the random search combined with the grid search to make predictions on the hold-out testing set. Remember, our model has never seen the test set before, so this metric should be a good indicator of how the model would perform if deployed in the real world. \n",
    "\n",
    "For comparison, we will again look at the performance of the default model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=60,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default model\n",
    "default_model = RandomForestRegressor(random_state = 42, n_jobs = -1)\n",
    "\n",
    "# Select the best model\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.n_jobs = -1\n",
    "\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 ms ± 10.6 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "default_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.99 s ± 973 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is quite a bit slower than the default (18 times slower on my machine). In a production setting, we would have to balance the increased run time against the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default model performance on the test set: MAE = 9.9946.\n",
      "Final model performance on the test set:   MAE = 9.4806.\n"
     ]
    }
   ],
   "source": [
    "default_pred = default_model.predict(X_test)\n",
    "final_pred = final_model.predict(X_test)\n",
    "\n",
    "print('Default model performance on the test set: MAE = %0.4f.' % mae(y_test, default_pred))\n",
    "print('Final model performance on the test set:   MAE = %0.4f.' % mae(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model does out-perform the baseline model by about 5%, but at the cost of significantly increased running time. Machine learning is often a field of tradeoffs: bias vs variance, acccuracy vs interpretability, accuracy vs running time, and the final decision depends on the use case. Here, I am find with the increase in run time because while the relative difference is large, the absolute magnitude of the training time is not significant. In a different situation, the balance might not be the same so we would need to consider what we are optimizing for and the limitations we have to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we saw how to evaluate several machine learning methods using the default parameters in scikit-learn. We compared the results of the models and selected the one that performed the best for hyperparameter tuning. We then optimized the hyperparameters using random search with cross validation and then grid search with cross validation. Finally, we took the final model and evaluate the performance on the test set. \n",
    "\n",
    "Based on the results, we can say that our model is able to predict the Energy Star Score of a building to within +- 9.48 points. We also saw that tuning the hyperparameters of the random forest did improve performance slightly, although there was a tradeoff in terms of time to train the model. \n",
    "\n",
    "The next step in the machine learning process is my favorite: trying to understand why the model makes the predictions it does. Achieveing high accuracy is great, but it would also be helpful if we could figure out why the model is able to predict accurately. What features does it rely on to infer the Energy Star Score? It is possible to use this model for feature selection and implement a simpler model that is more interpretable? In the final notebook, we will try to answer these questions and draw conclusions from the project that we can then apply to more machine learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
